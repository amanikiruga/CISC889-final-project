Adding dependency `anaconda/5.2.0:python3` to your environment
Adding package `svd3d/20231214` to your environment
Adding package `git/2.29.3` to your environment
unable to remove index 21181
NYU-GeoNet trainval: 7512 instances.
NYUv2 labeled test set: 654 instances
config file used /work/ececis_research/peace/DynamiCrafter/configs/inference_512_v1.0.yaml
[2024-04-18 18:41:29,188][mainlogger][INFO] - LatentVisualDiffusion: Running in v-prediction mode
DiffusionWrapper instantiating from {'target': 'lvdm.modules.networks.openaimodel3d.UNetModel', 'params': {'in_channels': 8, 'out_channels': 4, 'model_channels': 320, 'attention_resolutions': [4, 2, 1], 'num_res_blocks': 2, 'channel_mult': [1, 2, 4, 4], 'dropout': 0.1, 'num_head_channels': 64, 'transformer_depth': 1, 'context_dim': 1024, 'use_linear': True, 'use_checkpoint': False, 'temporal_conv': True, 'temporal_attention': True, 'temporal_selfatt_only': True, 'use_relative_position': False, 'use_causal_attention': False, 'temporal_length': 16, 'addition_attention': True, 'image_cross_attention': True, 'default_fs': 24, 'fs_condition': True}}
AE working on z of shape (1, 4, 32, 32) = 4096 dimensions.
[2024-04-18 18:41:42,332][root][INFO] - Loaded ViT-H-14 model config.
[2024-04-18 18:41:49,372][root][INFO] - Loading pretrained ViT-H-14 weights (laion2b_s32b_b79k).
Instantiating LatentVisualDiffusion
embedding model config: {'target': 'lvdm.modules.encoders.condition.FrozenOpenCLIPImageEmbedderV2', 'params': {'freeze': True}}
[2024-04-18 18:41:51,054][root][INFO] - Loaded ViT-H-14 model config.
[2024-04-18 18:41:57,775][root][INFO] - Loading pretrained ViT-H-14 weights (laion2b_s32b_b79k).
using custom UNetModel
>>> model checkpoint loaded.
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:43:38,092][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:43:38
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:43:54,667][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:43:54
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:44:01,694][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:44:01
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:44:08,749][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:44:08
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:44:15,803][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:44:15
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:44:22,868][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:44:22
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:44:29,924][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:44:29
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:44:36,999][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:44:37
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:44:44,095][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:44:44
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:44:51,190][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:44:51
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:44:58,285][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:44:58
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:45:05,365][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:45:05
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:45:12,453][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:45:12
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:45:19,548][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:45:19
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:45:26,656][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:45:26
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:45:33,751][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:45:33
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:45:40,827][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:45:40
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:45:47,916][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:45:47
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:45:55,036][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:45:55
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:46:02,138][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:46:02
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:46:09,232][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:46:09
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:46:16,329][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:46:16
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:46:23,438][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:46:23
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:46:30,551][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:46:30
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:46:37,659][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:46:37
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:46:44,752][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:46:44
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:46:51,864][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:46:51
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:46:58,981][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:46:59
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:47:06,082][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:47:06
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:47:13,192][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:47:13
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:47:20,294][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:47:20
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:47:27,396][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:47:27
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:47:34,490][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:47:34
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:47:41,604][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:47:41
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:47:48,717][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:47:48
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:47:55,831][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:47:55
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:48:02,927][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:48:02
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:48:10,020][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:48:10
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:48:17,133][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:48:17
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:48:24,264][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:48:24
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:48:31,370][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:48:31
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:48:38,474][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:48:38
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:48:45,590][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:48:45
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:48:52,719][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:48:52
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:48:59,806][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:48:59
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:49:06,912][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:49:06
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:49:14,021][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:49:14
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:49:21,130][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:49:21
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:49:28,240][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:49:28
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:49:35,335][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:49:35
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:49:42,446][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:49:42
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:49:49,556][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:49:49
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:49:56,678][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:49:56
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:50:03,800][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:50:03
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:50:10,899][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:50:10
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:50:18,014][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:50:18
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:50:25,111][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:50:25
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:50:32,215][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:50:32
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:50:39,323][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:50:39
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:50:46,426][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:50:46
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:50:53,522][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:50:53
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:51:00,627][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:51:00
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:51:07,712][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:51:07
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:51:14,793][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:51:14
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:51:21,896][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:51:21
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:51:29,005][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:51:29
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:51:36,107][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:51:36
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:51:43,212][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:51:43
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:51:50,312][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:51:50
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:51:57,409][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:51:57
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:52:04,502][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:52:04
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:52:11,611][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:52:11
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:52:18,707][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:52:18
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:52:25,811][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:52:25
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:52:32,905][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:52:32
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:52:39,997][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:52:40
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:52:47,087][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:52:47
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:52:54,204][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:52:54
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:53:01,285][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:53:01
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:53:08,385][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:53:08
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:53:15,494][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:53:15
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:53:22,585][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:53:22
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:53:29,687][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:53:29
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:53:36,794][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:53:36
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:53:43,892][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:53:43
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:53:50,984][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:53:51
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:53:58,081][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:53:58
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:54:05,173][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:54:05
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:54:12,266][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:54:12
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:54:19,367][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:54:19
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:54:26,463][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:54:26
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:54:33,585][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:54:33
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:54:40,701][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:54:40
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:54:47,816][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:54:47
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:54:54,935][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:54:54
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:55:02,034][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:55:02
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:55:09,132][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:55:09
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:55:16,253][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:55:16
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:55:23,357][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:55:23
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:55:30,476][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:55:30
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:55:37,594][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:55:37
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:55:44,708][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:55:44
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:55:51,803][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:55:51
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:55:58,914][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:55:58
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:56:06,022][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:56:06
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:56:13,117][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:56:13
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:56:20,226][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:56:20
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:56:27,322][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:56:27
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:56:34,418][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:56:34
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:56:41,514][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:56:41
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:56:48,596][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:56:48
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:56:55,711][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:56:55
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:57:02,813][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:57:02
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:57:09,916][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:57:09
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:57:17,028][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:57:17
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:57:24,133][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:57:24
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:57:31,220][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:57:31
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:57:38,319][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:57:38
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:57:45,428][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:57:45
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:57:52,538][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:57:52
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:57:59,612][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:57:59
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:58:06,708][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:58:06
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:58:13,797][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:58:13
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:58:20,927][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:58:20
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:58:28,040][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:58:28
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:58:35,171][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:58:35
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:58:42,285][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:58:42
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:58:49,390][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:58:49
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:58:56,503][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:58:56
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:59:03,636][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:59:03
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:59:10,737][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:59:10
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:59:17,847][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:59:17
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:59:24,953][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:59:24
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:59:32,076][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:59:32
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:59:39,195][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:59:39
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:59:46,296][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:59:46
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 18:59:53,430][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 18:59:53
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:00:00,526][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:00:00
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:00:07,627][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:00:07
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:00:14,717][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:00:14
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:00:21,803][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:00:21
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:00:28,883][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:00:28
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:00:35,991][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:00:36
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:00:43,094][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:00:43
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:00:50,195][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:00:50
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:00:57,316][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:00:57
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:01:04,457][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:01:04
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:01:11,554][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:01:11
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:01:18,661][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:01:18
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:01:25,745][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:01:25
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:01:32,813][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:01:32
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:01:39,903][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:01:39
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:01:47,018][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:01:47
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:01:54,097][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:01:54
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:02:01,193][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:02:01
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:02:08,290][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:02:08
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:02:15,385][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:02:15
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:02:22,454][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:02:22
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:02:29,554][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:02:29
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:02:36,664][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:02:36
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:02:43,755][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:02:43
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:02:50,845][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:02:50
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:02:57,951][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:02:57
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:03:05,023][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:03:05
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:03:12,119][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:03:12
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:03:19,194][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:03:19
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:03:26,278][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:03:26
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:03:33,365][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:03:33
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:03:40,461][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:03:40
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:03:47,559][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:03:47
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:03:54,669][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:03:54
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:04:01,777][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:04:01
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:04:08,854][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:04:08
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:04:15,958][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:04:15
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:04:23,038][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:04:23
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:04:30,116][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:04:30
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:04:37,209][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:04:37
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:04:44,323][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:04:44
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:04:51,415][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:04:51
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:04:58,517][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:04:58
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:05:05,607][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:05:05
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:05:12,695][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:05:12
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:05:19,771][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:05:19
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:05:26,854][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:05:26
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:05:33,946][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:05:33
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:05:41,045][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:05:41
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:05:48,135][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:05:48
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:05:55,258][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:05:55
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:06:02,359][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:06:02
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:06:09,464][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:06:09
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:06:16,575][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:06:16
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:06:23,671][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:06:23
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:06:30,742][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:06:30
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:06:37,825][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:06:37
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:06:44,900][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:06:44
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:06:51,987][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:06:52
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:06:59,084][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:06:59
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:07:06,172][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:07:06
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:07:13,276][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:07:13
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:07:20,359][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:07:20
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:07:27,447][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:07:27
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:07:34,552][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:07:34
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:07:41,632][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:07:41
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:07:48,706][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:07:48
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:07:55,804][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:07:55
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:08:02,894][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:08:02
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:08:10,005][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:08:10
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:08:17,088][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:08:17
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:08:24,189][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:08:24
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:08:31,292][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:08:31
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:08:38,389][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:08:38
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:08:45,494][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:08:45
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:08:52,602][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:08:52
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:08:59,687][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:08:59
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:09:06,780][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:09:06
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:09:13,872][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:09:13
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:09:20,962][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:09:20
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:09:28,038][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:09:28
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:09:35,127][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:09:35
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:09:42,231][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:09:42
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:09:49,329][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:09:49
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:09:56,420][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:09:56
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:10:03,488][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:10:03
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:10:10,575][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:10:10
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:10:17,660][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:10:17
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:10:24,753][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:10:24
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:10:31,836][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:10:31
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:10:38,936][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:10:38
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:10:46,032][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:10:46
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:10:53,108][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:10:53
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:11:00,193][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:11:00
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:11:07,297][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:11:07
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:11:14,390][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:11:14
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:11:21,487][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:11:21
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:11:28,595][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:11:28
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:11:35,690][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:11:35
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:11:42,788][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:11:42
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:11:49,871][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:11:49
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:11:56,981][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:11:57
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:12:04,086][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:12:04
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:12:11,162][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:12:11
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:12:18,275][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:12:18
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:12:25,387][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:12:25
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:12:32,490][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:12:32
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:12:39,588][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:12:39
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:12:46,684][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:12:46
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:12:53,775][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:12:53
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:13:00,867][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:13:00
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:13:07,963][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:13:07
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:13:15,059][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:13:15
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:13:22,148][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:13:22
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:13:29,223][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:13:29
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:13:36,306][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:13:36
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:13:43,383][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:13:43
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:13:50,475][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:13:50
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:13:57,554][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:13:57
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:14:04,657][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:14:04
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:14:11,773][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:14:11
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:14:18,851][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:14:18
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:14:25,970][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:14:26
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:14:33,058][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:14:33
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:14:40,165][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:14:40
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:14:47,263][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:14:47
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:14:54,364][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:14:54
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:15:01,474][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:15:01
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:15:08,572][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:15:08
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:15:15,687][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:15:15
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:15:22,780][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:15:22
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:15:29,887][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:15:29
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:15:36,977][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:15:37
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:15:44,073][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:15:44
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:15:51,156][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:15:51
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:15:58,263][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:15:58
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:16:05,366][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:16:05
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:16:12,445][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:16:12
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:16:19,513][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:16:19
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:16:26,611][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:16:26
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:16:33,715][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:16:33
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:16:40,821][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:16:40
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:16:47,919][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:16:47
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:16:54,997][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:16:55
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:17:02,077][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:17:02
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:17:09,149][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:17:09
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:17:16,252][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:17:16
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:17:23,358][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:17:23
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:17:30,452][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:17:30
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:17:37,537][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:17:37
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:17:44,609][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:17:44
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:17:51,706][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:17:51
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:17:58,798][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:17:58
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:18:05,882][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:18:05
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:18:12,961][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:18:12
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:18:20,030][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:18:20
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:18:27,099][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:18:27
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:18:34,189][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:18:34
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:18:41,281][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:18:41
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:18:48,380][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:18:48
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:18:55,481][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:18:55
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:19:02,565][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:19:02
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:19:09,654][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:19:09
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:19:16,749][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:19:16
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:19:23,840][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:19:23
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:19:30,927][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:19:30
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:19:38,014][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:19:38
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:19:45,105][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:19:45
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:19:52,198][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:19:52
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:19:59,300][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:19:59
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:20:06,389][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:20:06
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:20:13,480][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:20:13
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:20:20,590][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:20:20
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:20:27,688][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:20:27
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:20:34,783][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:20:34
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:20:41,876][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:20:41
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:20:48,987][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:20:49
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:20:56,077][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:20:56
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:21:03,187][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:21:03
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:21:10,271][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:21:10
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:21:17,364][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:21:17
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:21:24,462][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:21:24
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:21:31,565][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:21:31
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:21:38,662][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:21:38
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:21:45,765][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:21:45
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:21:52,868][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:21:52
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:21:59,967][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:21:59
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:22:07,060][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:22:07
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:22:14,158][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:22:14
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:22:21,249][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:22:21
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:22:28,354][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:22:28
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:22:35,447][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:22:35
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:22:42,524][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:22:42
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:22:49,633][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:22:49
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:22:56,737][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:22:56
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:23:03,835][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:23:03
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:23:10,925][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:23:10
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:23:18,031][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:23:18
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:23:25,123][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:23:25
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:23:32,217][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:23:32
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:23:39,336][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:23:39
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:23:46,422][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:23:46
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:23:53,502][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:23:53
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:24:00,593][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:24:00
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:24:07,697][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:24:07
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:24:14,786][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:24:14
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:24:21,875][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:24:21
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:24:28,993][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:24:29
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:24:36,072][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:24:36
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:24:43,174][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:24:43
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:24:50,245][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:24:50
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:24:57,346][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:24:57
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:25:04,454][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:25:04
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:25:11,566][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:25:11
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:25:18,653][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:25:18
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:25:25,745][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:25:25
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:25:32,864][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:25:32
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:25:39,960][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:25:39
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:25:47,063][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:25:47
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:25:54,163][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:25:54
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:26:01,269][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:26:01
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:26:08,379][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:26:08
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:26:15,483][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:26:15
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:26:22,563][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:26:22
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:26:29,665][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:26:29
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:26:36,779][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:26:36
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:26:43,875][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:26:43
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:26:50,979][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:26:51
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:26:58,077][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:26:58
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:27:05,187][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:27:05
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:27:12,297][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:27:12
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:27:19,390][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:27:19
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:27:26,482][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:27:26
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:27:33,591][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:27:33
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:27:40,672][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:27:40
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:27:47,775][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:27:47
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:27:54,876][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:27:54
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:28:01,966][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:28:01
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:28:09,068][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:28:09
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:28:16,169][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:28:16
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:28:23,275][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:28:23
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:28:30,363][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:28:30
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:28:37,455][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:28:37
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:28:44,568][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:28:44
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:28:51,649][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:28:51
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:28:58,736][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:28:58
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:29:05,842][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:29:05
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:29:12,937][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:29:12
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:29:20,034][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:29:20
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:29:27,136][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:29:27
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:29:34,215][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:29:34
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:29:41,319][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:29:41
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:29:48,413][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:29:48
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:29:55,503][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:29:55
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:30:02,607][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:30:02
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:30:09,697][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:30:09
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:30:16,789][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:30:16
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:30:23,890][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:30:23
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:30:31,002][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:30:31
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:30:38,103][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:30:38
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:30:45,199][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:30:45
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:30:52,310][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:30:52
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:30:59,418][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:30:59
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:31:06,511][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:31:06
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:31:13,621][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:31:13
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:31:20,709][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:31:20
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:31:27,813][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:31:27
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:31:34,921][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:31:34
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:31:42,040][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:31:42
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:31:49,130][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:31:49
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:31:56,206][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:31:56
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:32:03,289][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:32:03
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:32:10,365][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:32:10
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:32:17,474][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:32:17
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:32:24,569][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:32:24
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:32:31,677][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:32:31
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:32:38,796][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:32:38
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:32:45,904][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:32:45
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:32:53,014][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:32:53
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:33:00,116][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:33:00
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:33:07,215][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:33:07
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:33:14,308][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:33:14
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:33:21,384][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:33:21
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:33:28,459][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:33:28
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:33:35,555][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:33:35
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:33:42,663][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:33:42
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:33:49,767][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:33:49
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:33:56,855][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:33:56
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:34:03,970][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:34:03
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:34:11,085][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:34:11
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:34:18,176][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:34:18
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:34:25,289][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:34:25
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:34:32,372][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:34:32
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:34:39,472][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:34:39
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:34:46,568][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:34:46
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:34:53,659][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:34:53
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:35:00,744][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:35:00
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:35:07,847][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:35:07
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:35:14,963][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:35:14
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:35:22,064][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:35:22
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:35:29,163][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:35:29
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:35:36,268][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:35:36
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:35:43,355][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:35:43
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:35:50,472][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:35:50
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:35:57,583][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:35:57
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:36:04,665][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:36:04
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
images shape torch.Size([8, 3, 480, 480])
[2024-04-18 19:36:11,752][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 123
start: ['', '', '', '', '', '', '', ''] 2024-04-18 19:36:11
latent variables shape torch.Size([8, 4, 1, 40, 64])
cond_images shape torch.Size([8, 257, 1280])
img_emb shape torch.Size([8, 256, 1024])
sampling random noisy frames (8, 4, 16, 40, 64)
used exposed_timestep_index 0 time_range [19]
about to do inference... conditioning key is hybrid
shapes of intermediates x_inter ie. 'img' [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])] pred_x0 [torch.Size([8, 4, 16, 40, 64]), torch.Size([8, 4, 16, 40, 64])]
latent space images shape torch.Size([8, 4, 16, 40, 64])
intermediate keys dict_keys(['x_inter', 'pred_x0'])
